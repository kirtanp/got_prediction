{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sct = pd.read_json('data/GoT-screentimes.json')\n",
    "df_deaths = pd.read_csv('data/character-predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration \n",
    "**Data sources** \n",
    "* 'deaths' dataset from https://www.kaggle.com/mylesoneill/game-of-thrones\n",
    "* 'screentime' dataset from https://data.world/aendrew/game-of-thrones-screen-times\n",
    "\n",
    "Taking a first look at the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_info(df):\n",
    "    print(\"Column list: {}\".format(df.columns))\n",
    "    print(\"Shape: {}\".format(df.shape))\n",
    "    return(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column list: Index(['name', 'imdbUrl', 'screentime', 'episodes', 'portrayedBy'], dtype='object')\n",
      "Shape: (191, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>imdbUrl</th>\n",
       "      <th>screentime</th>\n",
       "      <th>episodes</th>\n",
       "      <th>portrayedBy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyrion Lannister</td>\n",
       "      <td>http://www.imdb.com/character/ch0146096/</td>\n",
       "      <td>293.30</td>\n",
       "      <td>54</td>\n",
       "      <td>{'name': 'Peter Dinklage', 'imdbUrl': 'http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jon Snow</td>\n",
       "      <td>http://www.imdb.com/character/ch0155777/</td>\n",
       "      <td>268.15</td>\n",
       "      <td>49</td>\n",
       "      <td>{'name': 'Kit Harington', 'imdbUrl': 'http://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daenerys Targaryen</td>\n",
       "      <td>http://www.imdb.com/character/ch0158597/</td>\n",
       "      <td>221.30</td>\n",
       "      <td>49</td>\n",
       "      <td>{'name': 'Emilia Clarke', 'imdbUrl': 'http://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cersei Lannister</td>\n",
       "      <td>http://www.imdb.com/character/ch0159526/</td>\n",
       "      <td>201.45</td>\n",
       "      <td>52</td>\n",
       "      <td>{'name': 'Lena Headey', 'imdbUrl': 'http://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sansa Stark</td>\n",
       "      <td>http://www.imdb.com/character/ch0158137/</td>\n",
       "      <td>199.30</td>\n",
       "      <td>47</td>\n",
       "      <td>{'name': 'Sophie Turner', 'imdbUrl': 'http://w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                   imdbUrl  screentime  \\\n",
       "0    Tyrion Lannister  http://www.imdb.com/character/ch0146096/      293.30   \n",
       "1            Jon Snow  http://www.imdb.com/character/ch0155777/      268.15   \n",
       "2  Daenerys Targaryen  http://www.imdb.com/character/ch0158597/      221.30   \n",
       "3    Cersei Lannister  http://www.imdb.com/character/ch0159526/      201.45   \n",
       "4         Sansa Stark  http://www.imdb.com/character/ch0158137/      199.30   \n",
       "\n",
       "  episodes                                        portrayedBy  \n",
       "0       54  {'name': 'Peter Dinklage', 'imdbUrl': 'http://...  \n",
       "1       49  {'name': 'Kit Harington', 'imdbUrl': 'http://w...  \n",
       "2       49  {'name': 'Emilia Clarke', 'imdbUrl': 'http://w...  \n",
       "3       52  {'name': 'Lena Headey', 'imdbUrl': 'http://www...  \n",
       "4       47  {'name': 'Sophie Turner', 'imdbUrl': 'http://w...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_info(df_sct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Peter Dinklage', 'imdbUrl': 'http://www.imdb.com/name/nm0227759/'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if we have gender as part of this dataset and what else we have in the portrayedBy dict\n",
    "df_sct['portrayedBy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column list: Index(['S.No', 'actual', 'pred', 'alive', 'plod', 'name', 'title', 'male',\n",
      "       'culture', 'dateOfBirth', 'DateoFdeath', 'mother', 'father', 'heir',\n",
      "       'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
      "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
      "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'boolDeadRelations',\n",
      "       'isPopular', 'popularity', 'isAlive'],\n",
      "      dtype='object')\n",
      "Shape: (1946, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>actual</th>\n",
       "      <th>pred</th>\n",
       "      <th>alive</th>\n",
       "      <th>plod</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>male</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>boolDeadRelations</th>\n",
       "      <th>isPopular</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.946</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.613</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>1</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.507</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.924</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.383</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>0</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No  actual  pred  alive   plod                  name  \\\n",
       "0     1       0     0  0.054  0.946  Viserys II Targaryen   \n",
       "1     2       1     0  0.387  0.613           Walder Frey   \n",
       "2     3       1     0  0.493  0.507          Addison Hill   \n",
       "3     4       0     0  0.076  0.924           Aemma Arryn   \n",
       "4     5       1     1  0.617  0.383        Sylva Santagar   \n",
       "\n",
       "                  title  male   culture  dateOfBirth  ...  isAliveHeir  \\\n",
       "0                   NaN     1       NaN          NaN  ...          0.0   \n",
       "1  Lord of the Crossing     1  Rivermen        208.0  ...          NaN   \n",
       "2                   Ser     1       NaN          NaN  ...          NaN   \n",
       "3                 Queen     0       NaN         82.0  ...          NaN   \n",
       "4            Greenstone     0   Dornish        276.0  ...          NaN   \n",
       "\n",
       "  isAliveSpouse isMarried isNoble   age numDeadRelations  boolDeadRelations  \\\n",
       "0           NaN         0       0   NaN               11                  1   \n",
       "1           1.0         1       1  97.0                1                  1   \n",
       "2           NaN         0       1   NaN                0                  0   \n",
       "3           0.0         1       1  23.0                0                  0   \n",
       "4           1.0         1       1  29.0                0                  0   \n",
       "\n",
       "   isPopular  popularity  isAlive  \n",
       "0          1    0.605351        0  \n",
       "1          1    0.896321        1  \n",
       "2          0    0.267559        1  \n",
       "3          0    0.183946        0  \n",
       "4          0    0.043478        1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_info(df_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining datasets\n",
    "The screentime dataset doesn't have much information by itself. Before we do any further exploration, we try to combine the screentime dataset with the deaths dataset based on the name column, after converting all names to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid  screentimes in screentime dataset\n",
      "\n",
      "True    191\n",
      "Name: screentime, dtype: int64\n",
      "\n",
      "Number of valid screentimes in combined dataset\n",
      "\n",
      "False    1820\n",
      "True      126\n",
      "Name: screentime, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_deaths['name'] = df_deaths['name'].str.lower()\n",
    "df_sct['name'] = df_sct['name'].str.lower()\n",
    "\n",
    "df_combined = pd.merge(df_deaths, df_sct, on='name', how='left')\n",
    "\n",
    "print(\"Number of valid  screentimes in screentime dataset\", df_sct['screentime'].notna().value_counts(), \n",
    "      \"Number of valid screentimes in combined dataset\", df_combined['screentime'].notna().value_counts(), \n",
    "      sep = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are missing 191 - 126 = 65 names which are in the screentime dataset but have not been mapped to any name in the deaths dataset. We try to take a look at these names to see possibly why they are not mapped and try to map a bit more of them before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"petyr 'littlefinger' baelish\", \"eddard 'ned' stark\", 'brienne of tarth', 'lord varys', \"sandor 'the hound' clegane\", 'ramsay bolton', 'tormund giantsbane', 'olenna tyrell', 'grand maester pycelle', 'talisa maegyr', 'robert baratheon', 'yara greyjoy', 'khal drogo', 'maester luwin', 'ros']\n"
     ]
    }
   ],
   "source": [
    "mapped_names = df_combined[df_combined.screentime.notna()].name\n",
    "unmapped_names = list(df_sct.query(\"name not in @mapped_names\").name)\n",
    "print(unmapped_names[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brienne of tarth', 'talisa maegyr', 'robert baratheon', 'yara greyjoy', 'jaqen hghar', 'ros', 'aemon', 'thoros of myr', 'locke', 'myranda'] \n",
      "\n",
      "Proportion of names mapped = 0.76\n"
     ]
    }
   ],
   "source": [
    "title_list = ['lord', 'maester', 'grand maester', 'khal', 'ser', 'septa', 'black']\n",
    "\n",
    "name_dict = {'ramsay bolton': 'ramsay snow',\n",
    "             'tormund giantsbane': 'tormund',\n",
    "             'olenna tyrell': 'olenna redwyne',\n",
    "             'smalljon umber': 'jon umber (smalljon)',\n",
    "             'greatjon umber': 'jon umber (greatjon)',\n",
    "             'selyse baratheon': 'selyse florent'\n",
    "             }\n",
    "\n",
    "def clean_name(name):\n",
    "    if('\\'' in name):\n",
    "        nick = name.split('\\'')\n",
    "        cleaned_name = nick[0].rstrip(' ') + nick[-1]\n",
    "        return(cleaned_name.strip())\n",
    "    for title in title_list:\n",
    "        if name.startswith(title):\n",
    "            return(name.lstrip(title).strip())\n",
    "    if(name in name_dict.keys()):\n",
    "        return(name_dict[name])\n",
    "    return(name)\n",
    "    \n",
    "df_sct['name'] = df_sct['name'].apply(clean_name)\n",
    "df_combined = pd.merge(df_deaths, df_sct, on='name', how='left')\n",
    "\n",
    "mapped_names = df_combined[df_combined.screentime.notna()].name\n",
    "unmapped_names = list(df_sct.query(\"name not in @mapped_names\").name)\n",
    "print(unmapped_names[:10], \"\\n\\nProportion of names mapped = {0:.2f}\".format(1-len(unmapped_names)/len(df_sct.name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having managed to map more than 3/4 th the names, we move on to exploring thie combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(columns=['imdbUrl', 'portrayedBy'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the data suitable for Survival analysis?\n",
    "While reading about what methods could be best for a problem of this nature, I learnt about survival analysis, and it fits perfectly. I was thinking that it is somehow not entirely reasonable to consider this a regular binary classification problem because the data for the living characters cannot be considered 'complete' and it seems strange to train on alive, dead as just 1, 0 as many of the alive characters might be very close or very far from their deaths and we have no knowledge of this. I had trouble formalizing this concept but I found a formalization in the language of Survival analysis, and it is right-censoring of the data.\n",
    "\n",
    "More info on survival analysis [here](https://www.cscu.cornell.edu/news/statnews/stnews78.pdf)\n",
    "\n",
    "**What do we need in the data to be able to use survival analysis?**\n",
    "\n",
    "*A timeline*: The process in our case is being alive. So the start date is the birth year, and the event of interest is death. The time passed until the start of the process is then clearly the age. We must check if we have the age for most characters which are alive, and at what age characters died.\n",
    "\n",
    "*Event times*: We would need to have an age of death for dead characters. We need to check how many of them we have this data for.\n",
    "\n",
    "*Current time*: We need to know where we are in the timeline, i.e. at what time in the game of thrones world this data si collected and if it is well defined and consistent for different characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 495 dead and 1451 living characters\n",
      "25.44% of the data is of dead characters\n",
      "32.73% of the dead characters have known age of death\n",
      "18.68% of the living characters have known age\n"
     ]
    }
   ],
   "source": [
    "data = df_combined\n",
    "num_dead = len(data[data.isAlive == 0].index)\n",
    "num_alive = len(data[data.isAlive == 1].index)\n",
    "print(\"There are {} dead and {} living characters\".format(num_dead, num_alive))\n",
    "\n",
    "dead_proportion = num_dead/(num_dead + num_alive)\n",
    "print(\"{0:.2f}% of the data is of dead characters\".format(100*dead_proportion))\n",
    "\n",
    "dead_with_age = len(data[(data.actual == 0) & (~data.age.isna())].index)/num_dead\n",
    "print(\"{0:.2f}% of the dead characters have known age of death\".format(100*dead_with_age))\n",
    "\n",
    "alive_with_age = len(data[(data.actual == 1) & (~data.age.isna())].index)/num_alive\n",
    "print(\"{0:.2f}% of the living characters have known age\".format(100*alive_with_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30;1m Stats for popular characters \u001b[0m\n",
      "There are 60 dead and 55 living characters\n",
      "52.17% of the data is of dead characters\n",
      "46.67% of the dead characters have known age of death\n",
      "69.09% of the living characters have known age\n"
     ]
    }
   ],
   "source": [
    "print(\"\\u001b[30;1m Stats for popular characters \\u001b[0m\")\n",
    "data_pop = data[data.isPopular == 1]\n",
    "num_dead = len(data_pop[data_pop.isAlive == 0].index)\n",
    "num_alive = len(data_pop[data_pop.isAlive == 1].index)\n",
    "print(\"There are {} dead and {} living characters\".format(num_dead, num_alive))\n",
    "\n",
    "dead_proportion = num_dead/(num_dead + num_alive)\n",
    "print(\"{0:.2f}% of the data is of dead characters\".format(100*dead_proportion))\n",
    "\n",
    "dead_with_age = len(data_pop[(data_pop.actual == 0) & (~data_pop.age.isna())].index)/num_dead\n",
    "print(\"{0:.2f}% of the dead characters have known age of death\".format(100*dead_with_age))\n",
    "\n",
    "alive_with_age = len(data_pop[(data_pop.actual == 1) & (~data_pop.age.isna())].index)/num_alive\n",
    "print(\"{0:.2f}% of the living characters have known age\".format(100*alive_with_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{305.0}\n"
     ]
    }
   ],
   "source": [
    "# Getting the 'current year'\n",
    "alive_with_age = data[(~data.age.isna()) & (data.isAlive == True) & (~data.dateOfBirth.isna())]\n",
    "print(set([age+DOB for age, DOB in zip(alive_with_age['age'], alive_with_age['dateOfBirth'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that even thought a large proportion of the dataset doesn't have age, we have it for a majority of the popular characters. Since we would mostly be interested in predicting deaths for popular characters, we go ahead with survival analysis. And also because I have not implemented survival analysis before and it would be an interesting exercise to do so.\n",
    "\n",
    "Since the 'current year' is well defined, we have a proper reference to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "* Since we are doing survival analysis, only look at rows which have a non null age\n",
    "* Look at columns with multiple similar strings for what should be the same value. This turns out to be a problem only in the 'culture' column\n",
    "* Remove columns we do not need to train\n",
    "* OneHotEncode the data\n",
    "* Fill nulls\n",
    "* Get the data to be trained on in the foramt required to use scikit-survival, described [here](https://nbviewer.jupyter.org/github/sebp/scikit-survival/blob/master/examples/00-introduction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From  Shail Daliwala's kernel on Kaggle\n",
    "cult = {\n",
    "    'Summer Islands': ['summer islands', 'summer islander', 'summer isles'],\n",
    "    'Ghiscari': ['ghiscari', 'ghiscaricari',  'ghis'],\n",
    "    'Asshai': [\"asshai'i\", 'asshai'],\n",
    "    'Lysene': ['lysene', 'lyseni'],\n",
    "    'Andal': ['andal', 'andals'],\n",
    "    'Braavosi': ['braavosi', 'braavos'],\n",
    "    'Dornish': ['dornishmen', 'dorne', 'dornish'],\n",
    "    'Myrish': ['myr', 'myrish', 'myrmen'],\n",
    "    'Westermen': ['westermen', 'westerman', 'westerlands'],\n",
    "    'Westerosi': ['westeros', 'westerosi'],\n",
    "    'Stormlander': ['stormlands', 'stormlander'],\n",
    "    'Norvoshi': ['norvos', 'norvoshi'],\n",
    "    'Northmen': ['the north', 'northmen'],\n",
    "    'Free Folk': ['wildling', 'first men', 'free folk'],\n",
    "    'Qartheen': ['qartheen', 'qarth'],\n",
    "    'Reach': ['the reach', 'reach', 'reachmen'],\n",
    "}\n",
    "\n",
    "def get_cult(value):\n",
    "    value = value.lower()\n",
    "    v = [k for (k, v) in cult.items() if value in v]\n",
    "    return v[0] if len(v) > 0 else value.title()\n",
    "\n",
    "data.loc[:, \"culture\"] = [get_cult(x) for x in data.culture.fillna(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_surv = data[(~data.age.isna()) & (data.age > 0)]  # Only using data with valid age values\n",
    "\n",
    "map_bool = {1: False, 0: True}\n",
    "data_surv_Y = [(map_bool[actual], age) for actual, age in zip(data_surv['actual'], data_surv['age'])]\n",
    "data_surv_Y = [tuple(y) for y in data_surv_Y]\n",
    "dt = np.dtype('?, int')\n",
    "data_surv_Y = np.array(data_surv_Y, dt)\n",
    "\n",
    "cols_dlt = ['actual', 'alive', 'name', 'plod', 'pred', 'isAlive', 'DateoFdeath', 'age', 'dateOfBirth', 'episodes', 'S.No']\n",
    "data_surv_X = data_surv.drop(cols_dlt, 1)\n",
    "\n",
    "for column in data_surv_X.columns:\n",
    "    df = data_surv_X[~data_surv_X[column].isna()]\n",
    "    if(len(df[column].value_counts()) <= 1):\n",
    "        data_surv_X.drop([column], 1, inplace=True)            \n",
    "\n",
    "\n",
    "data_surv_X.loc[:, \"title\"] = pd.factorize(data_surv_X.title)[0]\n",
    "data_surv_X.loc[:, \"house\"] = pd.factorize(data_surv_X.house)[0]\n",
    "data_surv_X.loc[:, \"spouse\"] = pd.factorize(data_surv_X.spouse)[0]\n",
    "#data_surv_X.loc[:, \"culture\"] = pd.factorize(data_surv_X.spouse)[0]\n",
    "\n",
    "for col in ['culture']:\n",
    "    data_surv_X[col] = data_surv_X[col].astype('category') \n",
    "\n",
    "data_surv_X = OneHotEncoder().fit_transform(data_surv_X)  \n",
    "\n",
    "data_surv_X.fillna(value = -1, inplace = True)\n",
    "\n",
    "for column in data_surv_X:\n",
    "    if(data_surv_X[column].astype(bool).sum(axis=0) <= 5):\n",
    "        data_surv_X.drop([column], 1, inplace=True)\n",
    "\n",
    "\n",
    "#data_surv_X['popularity'] = np.random.normal(0, 0.01, data_surv_X['popularity'].shape) + data_surv_X['popularity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival analysis\n",
    "We have the data_X and the data_Y as required in scikit-survival, we can now start to do. Since we have multiple variables, we use [Cox's proportional hazards model](https://en.wikipedia.org/wiki/Proportional_hazards_model) using the [scikit-survival](https://scikit-survival.readthedocs.io/en/latest/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6063895852785647"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_surv_X, data_surv_Y, test_size=0.2, random_state=62)\n",
    "\n",
    "estimator_cox = CoxPHSurvivalAnalysis()\n",
    "scores = cross_val_score(estimator_cox, X_train, y_train, cv=7)\n",
    "estimator_cox.fit(X_train, y_train)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               -0.004286\n",
       "male                 0.788561\n",
       "culture=Dornish     -0.438544\n",
       "culture=Free Folk    1.551378\n",
       "culture=Ironborn    -0.809795\n",
       "culture=Northmen     0.195294\n",
       "culture=Rivermen    -1.555390\n",
       "culture=Valemen      0.820255\n",
       "culture=Valyrian     0.367391\n",
       "culture=Westermen   -0.756967\n",
       "culture=Westerosi   -1.630534\n",
       "house               -0.000344\n",
       "spouse              -0.004810\n",
       "book1                0.263691\n",
       "book2                0.634710\n",
       "book3               -0.274606\n",
       "book4               -0.581907\n",
       "book5                0.233177\n",
       "isAliveSpouse        0.022055\n",
       "isMarried            0.338157\n",
       "isNoble             -0.501305\n",
       "numDeadRelations    -0.052483\n",
       "boolDeadRelations    0.940090\n",
       "isPopular           -0.005847\n",
       "popularity           0.653401\n",
       "screentime          -0.006939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(estimator_cox.coef_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_select__k</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.702113</td>\n",
       "      <td>0.105229</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>23</td>\n",
       "      <td>{'select__k': 23}</td>\n",
       "      <td>0.553654</td>\n",
       "      <td>0.669069</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.594388</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732940</td>\n",
       "      <td>0.698195</td>\n",
       "      <td>0.721160</td>\n",
       "      <td>0.717431</td>\n",
       "      <td>0.014427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.691850</td>\n",
       "      <td>0.102365</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>22</td>\n",
       "      <td>{'select__k': 22}</td>\n",
       "      <td>0.550879</td>\n",
       "      <td>0.662971</td>\n",
       "      <td>0.569128</td>\n",
       "      <td>0.594199</td>\n",
       "      <td>0.049092</td>\n",
       "      <td>2</td>\n",
       "      <td>0.728821</td>\n",
       "      <td>0.703084</td>\n",
       "      <td>0.710161</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>0.010856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.693189</td>\n",
       "      <td>0.103796</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>21</td>\n",
       "      <td>{'select__k': 21}</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.661308</td>\n",
       "      <td>0.572460</td>\n",
       "      <td>0.593358</td>\n",
       "      <td>0.049083</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720308</td>\n",
       "      <td>0.699323</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.711305</td>\n",
       "      <td>0.008822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.704519</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>20</td>\n",
       "      <td>{'select__k': 20}</td>\n",
       "      <td>0.551341</td>\n",
       "      <td>0.661308</td>\n",
       "      <td>0.557468</td>\n",
       "      <td>0.589926</td>\n",
       "      <td>0.050426</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>0.698822</td>\n",
       "      <td>0.714536</td>\n",
       "      <td>0.711954</td>\n",
       "      <td>0.009839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.724150</td>\n",
       "      <td>0.135323</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>26</td>\n",
       "      <td>{'select__k': 26}</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.650222</td>\n",
       "      <td>0.556913</td>\n",
       "      <td>0.586677</td>\n",
       "      <td>0.044860</td>\n",
       "      <td>5</td>\n",
       "      <td>0.739805</td>\n",
       "      <td>0.695562</td>\n",
       "      <td>0.717785</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.018062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.698549</td>\n",
       "      <td>0.105671</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>24</td>\n",
       "      <td>{'select__k': 24}</td>\n",
       "      <td>0.547179</td>\n",
       "      <td>0.641353</td>\n",
       "      <td>0.561355</td>\n",
       "      <td>0.583190</td>\n",
       "      <td>0.041444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.734038</td>\n",
       "      <td>0.709227</td>\n",
       "      <td>0.719410</td>\n",
       "      <td>0.720892</td>\n",
       "      <td>0.010183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.101651</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>19</td>\n",
       "      <td>{'select__k': 19}</td>\n",
       "      <td>0.550879</td>\n",
       "      <td>0.641353</td>\n",
       "      <td>0.556913</td>\n",
       "      <td>0.582954</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>7</td>\n",
       "      <td>0.715914</td>\n",
       "      <td>0.701830</td>\n",
       "      <td>0.714536</td>\n",
       "      <td>0.710760</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.697259</td>\n",
       "      <td>0.104729</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>25</td>\n",
       "      <td>{'select__k': 25}</td>\n",
       "      <td>0.552729</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.558023</td>\n",
       "      <td>0.579522</td>\n",
       "      <td>0.034307</td>\n",
       "      <td>8</td>\n",
       "      <td>0.739530</td>\n",
       "      <td>0.706093</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>0.721948</td>\n",
       "      <td>0.013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.658352</td>\n",
       "      <td>0.097007</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>18</td>\n",
       "      <td>{'select__k': 18}</td>\n",
       "      <td>0.548566</td>\n",
       "      <td>0.631929</td>\n",
       "      <td>0.555802</td>\n",
       "      <td>0.578678</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>9</td>\n",
       "      <td>0.710284</td>\n",
       "      <td>0.695437</td>\n",
       "      <td>0.714411</td>\n",
       "      <td>0.706711</td>\n",
       "      <td>0.008148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.512957</td>\n",
       "      <td>0.064490</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>17</td>\n",
       "      <td>{'select__k': 17}</td>\n",
       "      <td>0.546253</td>\n",
       "      <td>0.630820</td>\n",
       "      <td>0.555247</td>\n",
       "      <td>0.577349</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>10</td>\n",
       "      <td>0.708499</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.713911</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.007811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.481941</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>11</td>\n",
       "      <td>{'select__k': 11}</td>\n",
       "      <td>0.542091</td>\n",
       "      <td>0.626109</td>\n",
       "      <td>0.561632</td>\n",
       "      <td>0.576510</td>\n",
       "      <td>0.035894</td>\n",
       "      <td>11</td>\n",
       "      <td>0.698133</td>\n",
       "      <td>0.673499</td>\n",
       "      <td>0.697538</td>\n",
       "      <td>0.689723</td>\n",
       "      <td>0.011475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.478297</td>\n",
       "      <td>0.048411</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>12</td>\n",
       "      <td>{'select__k': 12}</td>\n",
       "      <td>0.536078</td>\n",
       "      <td>0.625554</td>\n",
       "      <td>0.566352</td>\n",
       "      <td>0.575878</td>\n",
       "      <td>0.037168</td>\n",
       "      <td>12</td>\n",
       "      <td>0.697103</td>\n",
       "      <td>0.673624</td>\n",
       "      <td>0.693163</td>\n",
       "      <td>0.687963</td>\n",
       "      <td>0.010266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493947</td>\n",
       "      <td>0.049749</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>5</td>\n",
       "      <td>{'select__k': 5}</td>\n",
       "      <td>0.531684</td>\n",
       "      <td>0.595898</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>0.574791</td>\n",
       "      <td>0.030619</td>\n",
       "      <td>13</td>\n",
       "      <td>0.652341</td>\n",
       "      <td>0.657515</td>\n",
       "      <td>0.641670</td>\n",
       "      <td>0.650509</td>\n",
       "      <td>0.006597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.477332</td>\n",
       "      <td>0.045942</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>6</td>\n",
       "      <td>{'select__k': 6}</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.616685</td>\n",
       "      <td>0.569406</td>\n",
       "      <td>0.572782</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>14</td>\n",
       "      <td>0.662158</td>\n",
       "      <td>0.640216</td>\n",
       "      <td>0.640295</td>\n",
       "      <td>0.647556</td>\n",
       "      <td>0.010325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475852</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>3</td>\n",
       "      <td>{'select__k': 3}</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>0.603381</td>\n",
       "      <td>0.564686</td>\n",
       "      <td>0.568731</td>\n",
       "      <td>0.026704</td>\n",
       "      <td>15</td>\n",
       "      <td>0.656392</td>\n",
       "      <td>0.610756</td>\n",
       "      <td>0.627734</td>\n",
       "      <td>0.631627</td>\n",
       "      <td>0.018833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.479542</td>\n",
       "      <td>0.047787</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>9</td>\n",
       "      <td>{'select__k': 9}</td>\n",
       "      <td>0.503469</td>\n",
       "      <td>0.664911</td>\n",
       "      <td>0.534981</td>\n",
       "      <td>0.567599</td>\n",
       "      <td>0.069856</td>\n",
       "      <td>16</td>\n",
       "      <td>0.687423</td>\n",
       "      <td>0.643788</td>\n",
       "      <td>0.666792</td>\n",
       "      <td>0.666001</td>\n",
       "      <td>0.017822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476094</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>4</td>\n",
       "      <td>{'select__k': 4}</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>0.594789</td>\n",
       "      <td>0.568295</td>\n",
       "      <td>0.567075</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>17</td>\n",
       "      <td>0.656666</td>\n",
       "      <td>0.630688</td>\n",
       "      <td>0.621047</td>\n",
       "      <td>0.636134</td>\n",
       "      <td>0.015043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.482511</td>\n",
       "      <td>0.049798</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>10</td>\n",
       "      <td>{'select__k': 10}</td>\n",
       "      <td>0.494218</td>\n",
       "      <td>0.648282</td>\n",
       "      <td>0.549972</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.063710</td>\n",
       "      <td>18</td>\n",
       "      <td>0.695936</td>\n",
       "      <td>0.647925</td>\n",
       "      <td>0.686789</td>\n",
       "      <td>0.676883</td>\n",
       "      <td>0.020814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.511239</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>16</td>\n",
       "      <td>{'select__k': 16}</td>\n",
       "      <td>0.506013</td>\n",
       "      <td>0.625277</td>\n",
       "      <td>0.556913</td>\n",
       "      <td>0.562569</td>\n",
       "      <td>0.048888</td>\n",
       "      <td>19</td>\n",
       "      <td>0.710971</td>\n",
       "      <td>0.684781</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.704096</td>\n",
       "      <td>0.013845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.511273</td>\n",
       "      <td>0.065624</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>15</td>\n",
       "      <td>{'select__k': 15}</td>\n",
       "      <td>0.503238</td>\n",
       "      <td>0.625277</td>\n",
       "      <td>0.555247</td>\n",
       "      <td>0.561085</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>20</td>\n",
       "      <td>0.706165</td>\n",
       "      <td>0.684781</td>\n",
       "      <td>0.715536</td>\n",
       "      <td>0.702161</td>\n",
       "      <td>0.012871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.493873</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>13</td>\n",
       "      <td>{'select__k': 13}</td>\n",
       "      <td>0.506938</td>\n",
       "      <td>0.620011</td>\n",
       "      <td>0.540255</td>\n",
       "      <td>0.555593</td>\n",
       "      <td>0.047446</td>\n",
       "      <td>21</td>\n",
       "      <td>0.698751</td>\n",
       "      <td>0.669738</td>\n",
       "      <td>0.701162</td>\n",
       "      <td>0.689884</td>\n",
       "      <td>0.014279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.494815</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>14</td>\n",
       "      <td>{'select__k': 14}</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.621397</td>\n",
       "      <td>0.540255</td>\n",
       "      <td>0.554968</td>\n",
       "      <td>0.049192</td>\n",
       "      <td>22</td>\n",
       "      <td>0.705753</td>\n",
       "      <td>0.675128</td>\n",
       "      <td>0.713286</td>\n",
       "      <td>0.698056</td>\n",
       "      <td>0.016501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>8</td>\n",
       "      <td>{'select__k': 8}</td>\n",
       "      <td>0.519658</td>\n",
       "      <td>0.614468</td>\n",
       "      <td>0.527762</td>\n",
       "      <td>0.553863</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>23</td>\n",
       "      <td>0.686256</td>\n",
       "      <td>0.643162</td>\n",
       "      <td>0.658105</td>\n",
       "      <td>0.662507</td>\n",
       "      <td>0.017866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.479444</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2</td>\n",
       "      <td>{'select__k': 2}</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.521655</td>\n",
       "      <td>0.553727</td>\n",
       "      <td>0.042309</td>\n",
       "      <td>24</td>\n",
       "      <td>0.631471</td>\n",
       "      <td>0.606744</td>\n",
       "      <td>0.613423</td>\n",
       "      <td>0.617213</td>\n",
       "      <td>0.010444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.479495</td>\n",
       "      <td>0.049749</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>7</td>\n",
       "      <td>{'select__k': 7}</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.607816</td>\n",
       "      <td>0.534425</td>\n",
       "      <td>0.553091</td>\n",
       "      <td>0.039237</td>\n",
       "      <td>25</td>\n",
       "      <td>0.679047</td>\n",
       "      <td>0.643287</td>\n",
       "      <td>0.657105</td>\n",
       "      <td>0.659813</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455612</td>\n",
       "      <td>0.051790</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1</td>\n",
       "      <td>{'select__k': 1}</td>\n",
       "      <td>0.549722</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.479178</td>\n",
       "      <td>0.540610</td>\n",
       "      <td>0.046788</td>\n",
       "      <td>26</td>\n",
       "      <td>0.586983</td>\n",
       "      <td>0.563119</td>\n",
       "      <td>0.569491</td>\n",
       "      <td>0.573198</td>\n",
       "      <td>0.010089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "22       0.702113      0.105229         0.004972        0.000198   \n",
       "21       0.691850      0.102365         0.005079        0.000256   \n",
       "20       0.693189      0.103796         0.005012        0.000163   \n",
       "19       0.704519      0.108674         0.005023        0.000203   \n",
       "25       0.724150      0.135323         0.005128        0.000148   \n",
       "23       0.698549      0.105671         0.005029        0.000220   \n",
       "18       0.687591      0.101651         0.005019        0.000219   \n",
       "24       0.697259      0.104729         0.005068        0.000107   \n",
       "17       0.658352      0.097007         0.004977        0.000218   \n",
       "16       0.512957      0.064490         0.001795        0.000025   \n",
       "10       0.481941      0.046537         0.001758        0.000032   \n",
       "11       0.478297      0.048411         0.001752        0.000035   \n",
       "4        0.493947      0.049749         0.001774        0.000041   \n",
       "5        0.477332      0.045942         0.001747        0.000043   \n",
       "2        0.475852      0.049154         0.001772        0.000038   \n",
       "8        0.479542      0.047787         0.001758        0.000015   \n",
       "3        0.476094      0.050193         0.001777        0.000036   \n",
       "9        0.482511      0.049798         0.001761        0.000033   \n",
       "15       0.511239      0.066498         0.001777        0.000063   \n",
       "14       0.511273      0.065624         0.001792        0.000056   \n",
       "12       0.493873      0.048599         0.001803        0.000087   \n",
       "13       0.494815      0.050918         0.001755        0.000070   \n",
       "7        0.494253      0.049444         0.001769        0.000032   \n",
       "1        0.479444      0.049707         0.001782        0.000047   \n",
       "6        0.479495      0.049749         0.001747        0.000036   \n",
       "0        0.455612      0.051790         0.001747        0.000053   \n",
       "\n",
       "   param_select__k             params  split0_test_score  split1_test_score  \\\n",
       "22              23  {'select__k': 23}           0.553654           0.669069   \n",
       "21              22  {'select__k': 22}           0.550879           0.662971   \n",
       "20              21  {'select__k': 21}           0.546716           0.661308   \n",
       "19              20  {'select__k': 20}           0.551341           0.661308   \n",
       "25              26  {'select__k': 26}           0.553191           0.650222   \n",
       "23              24  {'select__k': 24}           0.547179           0.641353   \n",
       "18              19  {'select__k': 19}           0.550879           0.641353   \n",
       "24              25  {'select__k': 25}           0.552729           0.628049   \n",
       "17              18  {'select__k': 18}           0.548566           0.631929   \n",
       "16              17  {'select__k': 17}           0.546253           0.630820   \n",
       "10              11  {'select__k': 11}           0.542091           0.626109   \n",
       "11              12  {'select__k': 12}           0.536078           0.625554   \n",
       "4                5   {'select__k': 5}           0.531684           0.595898   \n",
       "5                6   {'select__k': 6}           0.532609           0.616685   \n",
       "2                3   {'select__k': 3}           0.538390           0.603381   \n",
       "8                9   {'select__k': 9}           0.503469           0.664911   \n",
       "3                4   {'select__k': 4}           0.538390           0.594789   \n",
       "9               10  {'select__k': 10}           0.494218           0.648282   \n",
       "15              16  {'select__k': 16}           0.506013           0.625277   \n",
       "14              15  {'select__k': 15}           0.503238           0.625277   \n",
       "12              13  {'select__k': 13}           0.506938           0.620011   \n",
       "13              14  {'select__k': 14}           0.503700           0.621397   \n",
       "7                8   {'select__k': 8}           0.519658           0.614468   \n",
       "1                2   {'select__k': 2}           0.526133           0.613636   \n",
       "6                7   {'select__k': 7}           0.517345           0.607816   \n",
       "0                1   {'select__k': 1}           0.549722           0.592849   \n",
       "\n",
       "    split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "22           0.560800         0.594388        0.052772                1   \n",
       "21           0.569128         0.594199        0.049092                2   \n",
       "20           0.572460         0.593358        0.049083                3   \n",
       "19           0.557468         0.589926        0.050426                4   \n",
       "25           0.556913         0.586677        0.044860                5   \n",
       "23           0.561355         0.583190        0.041444                6   \n",
       "18           0.556913         0.582954        0.041277                7   \n",
       "24           0.558023         0.579522        0.034307                8   \n",
       "17           0.555802         0.578678        0.037688                9   \n",
       "16           0.555247         0.577349        0.037906               10   \n",
       "10           0.561632         0.576510        0.035894               11   \n",
       "11           0.566352         0.575878        0.037168               12   \n",
       "4            0.597168         0.574791        0.030619               13   \n",
       "5            0.569406         0.572782        0.034431               14   \n",
       "2            0.564686         0.568731        0.026704               15   \n",
       "8            0.534981         0.567599        0.069856               16   \n",
       "3            0.568295         0.567075        0.023057               17   \n",
       "9            0.549972         0.563953        0.063710               18   \n",
       "15           0.556913         0.562569        0.048888               19   \n",
       "14           0.555247         0.561085        0.050028               20   \n",
       "12           0.540255         0.555593        0.047446               21   \n",
       "13           0.540255         0.554968        0.049192               22   \n",
       "7            0.527762         0.553863        0.042889               23   \n",
       "1            0.521655         0.553727        0.042309               24   \n",
       "6            0.534425         0.553091        0.039237               25   \n",
       "0            0.479178         0.540610        0.046788               26   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "22            0.732940            0.698195            0.721160   \n",
       "21            0.728821            0.703084            0.710161   \n",
       "20            0.720308            0.699323            0.714286   \n",
       "19            0.722504            0.698822            0.714536   \n",
       "25            0.739805            0.695562            0.717785   \n",
       "23            0.734038            0.709227            0.719410   \n",
       "18            0.715914            0.701830            0.714536   \n",
       "24            0.739530            0.706093            0.720222   \n",
       "17            0.710284            0.695437            0.714411   \n",
       "16            0.708499            0.695312            0.713911   \n",
       "10            0.698133            0.673499            0.697538   \n",
       "11            0.697103            0.673624            0.693163   \n",
       "4             0.652341            0.657515            0.641670   \n",
       "5             0.662158            0.640216            0.640295   \n",
       "2             0.656392            0.610756            0.627734   \n",
       "8             0.687423            0.643788            0.666792   \n",
       "3             0.656666            0.630688            0.621047   \n",
       "9             0.695936            0.647925            0.686789   \n",
       "15            0.710971            0.684781            0.716535   \n",
       "14            0.706165            0.684781            0.715536   \n",
       "12            0.698751            0.669738            0.701162   \n",
       "13            0.705753            0.675128            0.713286   \n",
       "7             0.686256            0.643162            0.658105   \n",
       "1             0.631471            0.606744            0.613423   \n",
       "6             0.679047            0.643287            0.657105   \n",
       "0             0.586983            0.563119            0.569491   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "22          0.717431         0.014427  \n",
       "21          0.714022         0.010856  \n",
       "20          0.711305         0.008822  \n",
       "19          0.711954         0.009839  \n",
       "25          0.717718         0.018062  \n",
       "23          0.720892         0.010183  \n",
       "18          0.710760         0.006339  \n",
       "24          0.721948         0.013705  \n",
       "17          0.706711         0.008148  \n",
       "16          0.705907         0.007811  \n",
       "10          0.689723         0.011475  \n",
       "11          0.687963         0.010266  \n",
       "4           0.650509         0.006597  \n",
       "5           0.647556         0.010325  \n",
       "2           0.631627         0.018833  \n",
       "8           0.666001         0.017822  \n",
       "3           0.636134         0.015043  \n",
       "9           0.676883         0.020814  \n",
       "15          0.704096         0.013845  \n",
       "14          0.702161         0.012871  \n",
       "12          0.689884         0.014279  \n",
       "13          0.698056         0.016501  \n",
       "7           0.662507         0.017866  \n",
       "1           0.617213         0.010444  \n",
       "6           0.659813         0.014724  \n",
       "0           0.573198         0.010089  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis()\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores\n",
    "\n",
    "scores = fit_and_score_features(X_train.values, y_train)\n",
    "\n",
    "pipe = Pipeline([('select', SelectKBest(fit_and_score_features, k=3)),\n",
    "                 ('model', CoxPHSurvivalAnalysis())])\n",
    "\n",
    "param_grid = {'select__k': np.arange(1, X_train.shape[1] + 1)}\n",
    "gcv = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, iid=True)\n",
    "gcv.fit(X_train, y_train)\n",
    "\n",
    "pd.DataFrame(gcv.cv_results_).sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be any great insight in the table above. The best mean scores are for a large number of columns, so we just decide to keep them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.620429252782194"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = estimator_cox.predict(X_test)\n",
    "result = concordance_index_censored(y_test[\"f0\"], y_test[\"f1\"], prediction)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_s = pd.concat([data_surv[['name', 'age']], data_surv_X], axis=1)\n",
    "cols_to_keep = list(X_train.columns)\n",
    "surv_by_name = {}\n",
    "\n",
    "for name in result_s.name:\n",
    "    row_test = result_s[result_s.name == name]\n",
    "    row_test = row_test[cols_to_keep]\n",
    "    surv_by_name.update({name : estimator_cox.predict_survival_function(row_test)[0]})\n",
    "    \n",
    "result_s['survival_fn'] = result_s.apply(lambda row: surv_by_name[row['name']], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the results\n",
    "We start by taking a look at predictions for the most influential characters, and whether they are expected to survive 5 years from the 'current date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyrion lannister(age = 32.0): 0.9338720195408754\n",
      "jon snow(age = 22.0): 0.9130602979784419\n",
      "daenerys targaryen(age = 21.0): 0.9615599636601011\n",
      "cersei lannister(age = 39.0): 0.9570502315478597\n",
      "sansa stark(age = 19.0): 0.948703198372795\n",
      "arya stark(age = 16.0): 0.9493563966996424\n",
      "jaime lannister(age = 39.0): 0.8565344698058327\n",
      "theon greyjoy(age = 27.0): 0.7826085501183166\n",
      "samwell tarly(age = 22.0): 0.9554774360798821\n",
      "jorah mormont(age = 51.0): 0.3548877497250123\n",
      "petyr baelish(age = 37.0): 0.39813502106476223\n",
      "eddard stark(age = 36.0): 0.5764724792118956\n",
      "davos seaworth(age = 45.0): 0.8768504389142265\n",
      "bran stark(age = 15.0): 0.8324773853625015\n",
      "catelyn stark(age = 35.0): 0.9764412271506899\n",
      "tywin lannister(age = 58.0): 0.38446062932161656\n",
      "margaery tyrell(age = 22.0): 0.7705630176002121\n",
      "sandor clegane(age = 30.0): 0.44524331553005414\n",
      "ramsay snow(age = 23.0): 0.7691548195926595\n",
      "bronn(age = 41.0): 0.755548871928996\n",
      "gilly(age = 23.0): 0.35120607822712324\n",
      "ygritte(age = 19.0): 0.4799652327336576\n",
      "shae(age = 20.0): 0.900815164587622\n",
      "missandei(age = 17.0): 0.9674282802047901\n",
      "podrick payne(age = 19.0): 0.7986545129684622\n",
      "olenna redwyne(age = 77.0): 0.7365436607046654\n",
      "barristan selmy(age = 69.0): 0.8217079024080707\n",
      "pycelle(age = 84.0): 0.37207384861463294\n",
      "loras tyrell(age = 23.0): 0.6106925044468515\n",
      "roose bolton(age = 45.0): 0.3277277699564877\n"
     ]
    }
   ],
   "source": [
    "for name in result_s.nlargest(30, 'screentime').name:\n",
    "    row = result_s[result_s.name == name]\n",
    "    i = row.index[0]\n",
    "    age = row.at[i, 'age']\n",
    "    fn = row.at[i, 'survival_fn']\n",
    "    print('{}(age = {}):'.format(name, age), fn(age+5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion for survival analysis**\n",
    "\n",
    "We can see that the results are not great at all. Age seems to be the most important characteristic considered in calculating the probability of death, which makes sense. However, perhaps we did not have enough data to consider how the other characteristics would affect the survival, and we did not spend too much effort on tuning the model either. We also must keep in mind that the data is based on the fantasy world created in the mind of a single person which entertains party though surprising turns of events, which might inherently make it hard to find a pattern, or a general rule of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification\n",
    "We also do a quick binary classification for the sake of completeness, since we ignored many characters in the survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = data.actual.values\n",
    "\n",
    "cols_dlt = ['actual', 'alive', 'name', 'plod', 'pred', 'isAlive', 'DateoFdeath', 'dateOfBirth', 'S.No']\n",
    "data_X = data.drop(cols_dlt, 1)\n",
    "\n",
    "for column in data_X.columns:\n",
    "    df = data_X[~data_X[column].isna()]\n",
    "    if(len(df[column].value_counts()) <= 1):\n",
    "        data_X.drop([column], 1, inplace=True)            \n",
    "\n",
    "cols_to_factor = [col for col in data_X.select_dtypes('object')] \n",
    "for col in cols_to_factor:\n",
    "    data_X.loc[:, col] = pd.factorize(data_X[col])[0]\n",
    "\n",
    "data_X.fillna(value = -1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7885712821437626\n"
     ]
    }
   ],
   "source": [
    "estimator_lr = LogisticRegression(solver = 'lbfgs', max_iter = 10000)\n",
    "scores_lr = cross_val_score(estimator_lr, X_train, y_train, cv=7)\n",
    "estimator_lr.fit(X_train, y_train)\n",
    "print(scores_lr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is alreay a seemingly much better result than we had with survival analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7654109589041096"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyrion lannister(age = 32.0): 1\n",
      "jon snow(age = 22.0): 1\n",
      "daenerys targaryen(age = 21.0): 1\n",
      "cersei lannister(age = 39.0): 1\n",
      "sansa stark(age = 19.0): 1\n",
      "arya stark(age = 16.0): 1\n",
      "jaime lannister(age = 39.0): 1\n",
      "theon greyjoy(age = 27.0): 1\n",
      "samwell tarly(age = 22.0): 1\n",
      "jorah mormont(age = 51.0): 1\n",
      "petyr baelish(age = 37.0): 1\n",
      "eddard stark(age = 36.0): 1\n",
      "davos seaworth(age = 45.0): 1\n",
      "bran stark(age = 15.0): 1\n",
      "catelyn stark(age = 35.0): 1\n",
      "varys(age = -1.0): 1\n",
      "tywin lannister(age = 58.0): 0\n",
      "margaery tyrell(age = 22.0): 0\n",
      "robb stark(age = -1.0): 0\n",
      "stannis baratheon(age = -1.0): 0\n",
      "sandor clegane(age = 30.0): 1\n",
      "joffrey baratheon(age = -1.0): 0\n",
      "ramsay snow(age = 23.0): 1\n",
      "melisandre(age = -1.0): 1\n",
      "bronn(age = 41.0): 1\n",
      "gilly(age = 23.0): 1\n",
      "ygritte(age = 19.0): 1\n",
      "shae(age = 20.0): 1\n",
      "daario naharis(age = -1.0): 1\n",
      "missandei(age = 17.0): 1\n"
     ]
    }
   ],
   "source": [
    "result_lr = pd.concat([data[['name']], data_X], axis=1)\n",
    "result_lr['prediction_lr'] = estimator_lr.predict(data_X)\n",
    "\n",
    "for name in result_lr.nlargest(30, 'screentime').name:\n",
    "    row = result_lr[result_lr.name == name]\n",
    "    i = row.index[0]\n",
    "    age = row.at[i, 'age']\n",
    "    prediction = row.at[i, 'prediction_lr']\n",
    "    print('{}(age = {}):'.format(name, age), prediction )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of fairness\n",
    "We try to design a couple of simple measures of fairness to see the bias of gender in making the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Coeffecient for gender in the cox model**\n",
    "\n",
    "The easiest to see is the coeffecient corresponding to the colum 'male' in the trained survival analysis model we had. In case of gender not being important to the prediction, the coefficient should be zero, since the coefficient is the log of the hazard (how more likely you are likely to die if the value of this variable is true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hazard ratio of being male is 2.2002279506551092\n"
     ]
    }
   ],
   "source": [
    "coeff_gender = pd.Series(estimator_cox.coef_, index=X_train.columns)['male']\n",
    "\n",
    "e = math.e\n",
    "print('The hazard ratio of being male is {}'.format(e**(coeff_gender)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that the farther this number if from 1, the more the bias is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Expect 'similar' predictions for 'similar' features apart from gender**\n",
    "\n",
    "Most measures of fairness will have a measure of similarity associated with them, to formalize who want things to be fair for, before we can formalize what we call fair. \n",
    "\n",
    "What we want in this problem is for the algorithm to predict death with similar probability for each of the groups 'male' and 'female', other things being equal. We can define 'other things being equal' in many ways. We could look at the titles of the characters, or the houses they belong to or what age group they are it, or  combination of these. We go with the following:\n",
    "\n",
    "**Definition:** Given a fixed value of the attribute isPopular, the average of the predictions from the logistic regression model trained above should be similar for the groups with attributes gender=male and gender=female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fair = result_lr[['isPopular', 'male', 'prediction_lr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prediction_lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isPopular</th>\n",
       "      <th>male</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.960055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.919457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prediction_lr\n",
       "isPopular male               \n",
       "0         0          0.960055\n",
       "          1          0.919457\n",
       "1         0          0.733333\n",
       "          1          0.430000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_fair.groupby(['isPopular', 'male']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a significant difference in the avegrage expectation of death according the the regression model for popolar characters. However, without further analyis, it is hard to read much into this conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
